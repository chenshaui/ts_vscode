{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNewDataByPandas():\n",
    "    wine = pd.read_csv(\"./wine.csv\")\n",
    "    wine['alcohol**2'] = pow(wine[\"alcohol\"], 2)\n",
    "    wine['volatileAcidity*alcohol'] = wine[\"alcohol\"] * wine['volatile acidity']\n",
    "    y = np.array(wine.quality)\n",
    "    X = np.array(wine.drop(\"quality\", axis=1))\n",
    "\n",
    "    columns = np.array(wine.columns)\n",
    "\n",
    "    return X, y, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] File ./wine_lightgbm_train.bin exists, cannot save binary to it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x1a18332b910>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Read wine quality data from file\n",
    "X, y, wineNames = GetNewDataByPandas()\n",
    "\n",
    "# split data to [[0.8,0.2],01]\n",
    "x_train_all, x_predict, y_train_all, y_predict = train_test_split(X, y, test_size=0.10, random_state=100)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_all, y_train_all, test_size=0.2, random_state=100)\n",
    "\n",
    "train_data = lgb.Dataset(data=x_train,label=y_train)\n",
    "test_data = lgb.Dataset(data=x_test,label=y_test)\n",
    "\n",
    "train_data.save_binary(\"./wine_lightgbm_train.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以在lightgbm加载数据的时候同时指明类别特征，这对模型精度提升有一定的好处。\n",
    "# train_data = lgb.Dataset(data, label=label, feature_name=['c1', 'c2', 'c3'], categorical_feature=['c3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves':31, 'num_trees':100, 'objective':'regression'}\n",
    "param['metric'] = 'rmse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1308\n",
      "[LightGBM] [Info] Number of data points in the train set: 1151, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 5.608167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.conda\\envs\\torch_env\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "# Training a model requires a parameter list and data set:\n",
    "num_round = 10\n",
    "bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])\n",
    "# After training, the model can be saved:\n",
    "bst.save_model('model.txt')\n",
    "# A saved model can be loaded:\n",
    "bst = lgb.Booster(model_file='model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.conda\\envs\\torch_env\\lib\\site-packages\\lightgbm\\engine.py:685: UserWarning: Found 'num_trees' in params. Will use it instead of 'num_boost_round' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'num_boost_round' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1308\n",
      "[LightGBM] [Info] Number of data points in the train set: 920, number of used features: 13\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1308\n",
      "[LightGBM] [Info] Number of data points in the train set: 921, number of used features: 13\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1308\n",
      "[LightGBM] [Info] Number of data points in the train set: 921, number of used features: 13\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1308\n",
      "[LightGBM] [Info] Number of data points in the train set: 921, number of used features: 13\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1308\n",
      "[LightGBM] [Info] Number of data points in the train set: 921, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 5.606522\n",
      "[LightGBM] [Info] Start training from score 5.610206\n",
      "[LightGBM] [Info] Start training from score 5.609121\n",
      "[LightGBM] [Info] Start training from score 5.609121\n",
      "[LightGBM] [Info] Start training from score 5.605863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'valid rmse-mean': [0.774987106820873,\n",
       "  0.7491220863708051,\n",
       "  0.7281922212930283,\n",
       "  0.7097824692770105,\n",
       "  0.6940759739607876,\n",
       "  0.6797153946092306,\n",
       "  0.6696840593771072,\n",
       "  0.6609663890335338,\n",
       "  0.6535890703363206,\n",
       "  0.6473198288767565,\n",
       "  0.6425806790148506,\n",
       "  0.6373665111602508,\n",
       "  0.6347244528484731,\n",
       "  0.6308625770807975,\n",
       "  0.628918594642353,\n",
       "  0.6272230212085251,\n",
       "  0.6253250770201633,\n",
       "  0.6223593012391595,\n",
       "  0.6212648873132847,\n",
       "  0.6199514729892114,\n",
       "  0.6203873284980943,\n",
       "  0.6203033852456977,\n",
       "  0.6189822624878787,\n",
       "  0.6183410979829776,\n",
       "  0.6181484102219923,\n",
       "  0.6180162127636785,\n",
       "  0.6177792986445303,\n",
       "  0.6174518337809696,\n",
       "  0.617555391334362,\n",
       "  0.6162424295549256,\n",
       "  0.6167122570640725,\n",
       "  0.6163427083126598,\n",
       "  0.6159321116214705,\n",
       "  0.616212019117553,\n",
       "  0.6165976887053624,\n",
       "  0.6158503087885474,\n",
       "  0.6149133667697786,\n",
       "  0.6149134893419984,\n",
       "  0.6145255939620513,\n",
       "  0.6149597021436323,\n",
       "  0.6153579614072315,\n",
       "  0.6160740480612332,\n",
       "  0.6168216684639328,\n",
       "  0.6164941580283196,\n",
       "  0.6170504164797265,\n",
       "  0.6177888581767468,\n",
       "  0.617798948273026,\n",
       "  0.6179842663819789,\n",
       "  0.6171792114240351,\n",
       "  0.6176275192366131,\n",
       "  0.6174936994733722,\n",
       "  0.6168497946597541,\n",
       "  0.6169280890324067,\n",
       "  0.617170617278423,\n",
       "  0.6174549081460372,\n",
       "  0.6175894778791552,\n",
       "  0.6178172281511458,\n",
       "  0.6177074356867365,\n",
       "  0.6173532842864146,\n",
       "  0.6177117097492548,\n",
       "  0.6177916105095222,\n",
       "  0.6180637155019371,\n",
       "  0.6182706377614324,\n",
       "  0.618602216147406,\n",
       "  0.6184512933122821,\n",
       "  0.6184354585752795,\n",
       "  0.6185508415220242,\n",
       "  0.6189115668669214,\n",
       "  0.6189448327769184,\n",
       "  0.6192579397671489,\n",
       "  0.6192915033291009,\n",
       "  0.6195394304657093,\n",
       "  0.619669743808946,\n",
       "  0.6195191307815561,\n",
       "  0.6198992417746416,\n",
       "  0.6199676042183155,\n",
       "  0.6203491490475165,\n",
       "  0.6207130209177933,\n",
       "  0.6212884854505536,\n",
       "  0.6213148068910419,\n",
       "  0.621760814386622,\n",
       "  0.6219824799039468,\n",
       "  0.6219303931942972,\n",
       "  0.6220042757339039,\n",
       "  0.6218971497589291,\n",
       "  0.622359812398237,\n",
       "  0.6226282309246232,\n",
       "  0.6230148878816524,\n",
       "  0.623523571110041,\n",
       "  0.6237061782188509,\n",
       "  0.623988491678156,\n",
       "  0.6241353389553158,\n",
       "  0.6241092445459002,\n",
       "  0.6240719875959252,\n",
       "  0.6246752029727032,\n",
       "  0.6246856222955802,\n",
       "  0.6245883651549581,\n",
       "  0.6248084104751709,\n",
       "  0.6249892046029559,\n",
       "  0.625125156053759],\n",
       " 'valid rmse-stdv': [0.0017254872338815686,\n",
       "  0.0038675424010196705,\n",
       "  0.005950822899357324,\n",
       "  0.008990774822655348,\n",
       "  0.011475319496834975,\n",
       "  0.013256368425348912,\n",
       "  0.014491011360567813,\n",
       "  0.01578051477535458,\n",
       "  0.016068790473798715,\n",
       "  0.01695224371346207,\n",
       "  0.017697763437108594,\n",
       "  0.018990390334432613,\n",
       "  0.019484864750710835,\n",
       "  0.019332949937333237,\n",
       "  0.02013052267486151,\n",
       "  0.02108896587213228,\n",
       "  0.021815863356611245,\n",
       "  0.02289926745972188,\n",
       "  0.02377121010968826,\n",
       "  0.02422602388108883,\n",
       "  0.023695844677059222,\n",
       "  0.02355385586785252,\n",
       "  0.024397403498532932,\n",
       "  0.02471284110472985,\n",
       "  0.025269908724440078,\n",
       "  0.025635960801652966,\n",
       "  0.02576782533691033,\n",
       "  0.02597070860011001,\n",
       "  0.025777669057233103,\n",
       "  0.025786570868841535,\n",
       "  0.026048801414196965,\n",
       "  0.02649273918102944,\n",
       "  0.027067857610055476,\n",
       "  0.02729671461272282,\n",
       "  0.02714692754545433,\n",
       "  0.027710119280456413,\n",
       "  0.02813730885798961,\n",
       "  0.028077382125134744,\n",
       "  0.028557326858301365,\n",
       "  0.028839425353313193,\n",
       "  0.02877320161353734,\n",
       "  0.029106582075613802,\n",
       "  0.02932738564297258,\n",
       "  0.029795890865807993,\n",
       "  0.029801630514241603,\n",
       "  0.02952292591132153,\n",
       "  0.029089207656696273,\n",
       "  0.028970770194417447,\n",
       "  0.029599729690830596,\n",
       "  0.029782990851924037,\n",
       "  0.03004103947864575,\n",
       "  0.03014768555685702,\n",
       "  0.030168481636991828,\n",
       "  0.02973151800696227,\n",
       "  0.0296276323770722,\n",
       "  0.029385956697611428,\n",
       "  0.02940631339140006,\n",
       "  0.029349794575802054,\n",
       "  0.029480548294050602,\n",
       "  0.029522434255395354,\n",
       "  0.030254475198115742,\n",
       "  0.030028362450277724,\n",
       "  0.02994000749940138,\n",
       "  0.029949827179058357,\n",
       "  0.030282125718863413,\n",
       "  0.03014191038664315,\n",
       "  0.029858677446900815,\n",
       "  0.029624094074877465,\n",
       "  0.029327776521125358,\n",
       "  0.029677337793262457,\n",
       "  0.029894661338686658,\n",
       "  0.029869113988806036,\n",
       "  0.030283424467992568,\n",
       "  0.030588610707034024,\n",
       "  0.030628781150760242,\n",
       "  0.030719899781015317,\n",
       "  0.030333461970177444,\n",
       "  0.02981301388433991,\n",
       "  0.029664835243322637,\n",
       "  0.029764143919496364,\n",
       "  0.029886572204732773,\n",
       "  0.030135313752295664,\n",
       "  0.03017699657047771,\n",
       "  0.030121588207677123,\n",
       "  0.029854447401063626,\n",
       "  0.030230491592597213,\n",
       "  0.030245113683840197,\n",
       "  0.03060669973068252,\n",
       "  0.030994159688390283,\n",
       "  0.03110014993102391,\n",
       "  0.03095331750242449,\n",
       "  0.03078228686297496,\n",
       "  0.030987943618622674,\n",
       "  0.03114447006422773,\n",
       "  0.0313036813726971,\n",
       "  0.031529315005399954,\n",
       "  0.03145820611733882,\n",
       "  0.03164419397750484,\n",
       "  0.03191531705469107,\n",
       "  0.032204811799610863]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_round = 10\n",
    "lgb.cv(param, train_data, num_round, nfold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1308\n",
      "[LightGBM] [Info] Number of data points in the train set: 1151, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 5.608167\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's rmse: 0.568264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.conda\\envs\\torch_env\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1a183359190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 早停阈值则通过early_stopping_rounds\n",
    "param = {'num_leaves':31, 'num_trees':100, 'objective':'regression', 'early_stopping_rounds': 10}\n",
    "param['metric'] = 'rmse'\n",
    "bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])\n",
    "bst.save_model('model.txt', num_iteration=bst.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of predict : 0.5956830546692128\n"
     ]
    }
   ],
   "source": [
    "ypred = bst.predict(x_predict, num_iteration=bst.best_iteration)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE = np.sqrt(mean_squared_error(y_predict, ypred))\n",
    "\n",
    "print(\"RMSE of predict :\",RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
